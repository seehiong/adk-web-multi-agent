{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "868650b7",
   "metadata": {},
   "source": [
    "# Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d00b4809",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.adk.agents import Agent\n",
    "from google.adk.models.lite_llm import LiteLlm\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.runners import Runner\n",
    "from google.genai import types\n",
    "from typing import Optional, Dict\n",
    "from toolbox_core import ToolboxSyncClient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d53fb4",
   "metadata": {},
   "source": [
    "# Define the model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d8d8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelResponse(id='gen-1762062123-Fidsex2Fle0ZV8difSs3', created=1762062124, model='z-ai/glm-4.5-air:free', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=\"\\nHello! ðŸ‘‹ How can I assist you today? Feel free to ask any question or share what's on your mind!\", role='assistant', tool_calls=None, function_call=None, reasoning_content='Okay, the user just said \"Hello\". That\\'s a simple greeting. I need to respond warmly and invitingly to make them feel comfortable. \\n\\nHmm, since they didn\\'t provide any specific context or question, they might be testing the waters or starting a casual conversation. Maybe they\\'re unsure how to begin. I should keep it open-ended but friendly. \\n\\nI recall that in my guidelines, I\\'m supposed to be concise but helpful. Adding an emoji could make it feel more approachable. The smiley face seems rightâ€”it\\'s universal and not too formal. \\n\\nThe phrase \"How can I assist you today?\" covers all possibilities: they might need help, have a question, or just want to chat. It\\'s better than assuming. \\n\\n...Wait, should I ask about their name? Nah, that might feel intrusive if they\\'re just greeting me casually. Keep it simple. \\n\\nFinal decision: Friendly greeting + open-ended question + emoji. Done.', provider_specific_fields={'refusal': None, 'reasoning': 'Okay, the user just said \"Hello\". That\\'s a simple greeting. I need to respond warmly and invitingly to make them feel comfortable. \\n\\nHmm, since they didn\\'t provide any specific context or question, they might be testing the waters or starting a casual conversation. Maybe they\\'re unsure how to begin. I should keep it open-ended but friendly. \\n\\nI recall that in my guidelines, I\\'m supposed to be concise but helpful. Adding an emoji could make it feel more approachable. The smiley face seems rightâ€”it\\'s universal and not too formal. \\n\\nThe phrase \"How can I assist you today?\" covers all possibilities: they might need help, have a question, or just want to chat. It\\'s better than assuming. \\n\\n...Wait, should I ask about their name? Nah, that might feel intrusive if they\\'re just greeting me casually. Keep it simple. \\n\\nFinal decision: Friendly greeting + open-ended question + emoji. Done.', 'reasoning_details': [{'type': 'reasoning.text', 'text': 'Okay, the user just said \"Hello\". That\\'s a simple greeting. I need to respond warmly and invitingly to make them feel comfortable. \\n\\nHmm, since they didn\\'t provide any specific context or question, they might be testing the waters or starting a casual conversation. Maybe they\\'re unsure how to begin. I should keep it open-ended but friendly. \\n\\nI recall that in my guidelines, I\\'m supposed to be concise but helpful. Adding an emoji could make it feel more approachable. The smiley face seems rightâ€”it\\'s universal and not too formal. \\n\\nThe phrase \"How can I assist you today?\" covers all possibilities: they might need help, have a question, or just want to chat. It\\'s better than assuming. \\n\\n...Wait, should I ask about their name? Nah, that might feel intrusive if they\\'re just greeting me casually. Keep it simple. \\n\\nFinal decision: Friendly greeting + open-ended question + emoji. Done.', 'format': 'unknown', 'index': 0}], 'reasoning_content': 'Okay, the user just said \"Hello\". That\\'s a simple greeting. I need to respond warmly and invitingly to make them feel comfortable. \\n\\nHmm, since they didn\\'t provide any specific context or question, they might be testing the waters or starting a casual conversation. Maybe they\\'re unsure how to begin. I should keep it open-ended but friendly. \\n\\nI recall that in my guidelines, I\\'m supposed to be concise but helpful. Adding an emoji could make it feel more approachable. The smiley face seems rightâ€”it\\'s universal and not too formal. \\n\\nThe phrase \"How can I assist you today?\" covers all possibilities: they might need help, have a question, or just want to chat. It\\'s better than assuming. \\n\\n...Wait, should I ask about their name? Nah, that might feel intrusive if they\\'re just greeting me casually. Keep it simple. \\n\\nFinal decision: Friendly greeting + open-ended question + emoji. Done.'}), provider_specific_fields={'native_finish_reason': 'stop'})], usage=Usage(completion_tokens=223, prompt_tokens=6, total_tokens=229, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=231, rejected_prediction_tokens=None, text_tokens=None, image_tokens=0), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=4, text_tokens=None, image_tokens=None), cost=0, is_byok=False, cost_details={'upstream_inference_cost': None, 'upstream_inference_prompt_cost': 0, 'upstream_inference_completions_cost': 0}), provider='Z.AI')\n",
      "\n",
      "OpenRouter is ready for use.\n"
     ]
    }
   ],
   "source": [
    "MODEL = \"openrouter/z-ai/glm-4.5-air:free\"\n",
    "llm = LiteLlm(model=MODEL)\n",
    "\n",
    "# Test LLM with a direct call\n",
    "print(llm.llm_client.completion(model=llm.model, \n",
    "                                messages=[{\"role\": \"user\", \"content\": \"Hello\"}], \n",
    "                                tools=[]))\n",
    "\n",
    "print(\"\\nOpenRouter is ready for use.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429ba8de",
   "metadata": {},
   "source": [
    "# Load the tools from the MCP Toolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bff87d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded [<toolbox_core.sync_tool.ToolboxSyncTool object at 0x0000020984C92060>, <toolbox_core.sync_tool.ToolboxSyncTool object at 0x0000020985F62CC0>, <toolbox_core.sync_tool.ToolboxSyncTool object at 0x0000020984BF27E0>, <toolbox_core.sync_tool.ToolboxSyncTool object at 0x0000020985FA1040>, <toolbox_core.sync_tool.ToolboxSyncTool object at 0x0000020985FA0F20>, <toolbox_core.sync_tool.ToolboxSyncTool object at 0x0000020985FA0F50>] tools from MCP server\n"
     ]
    }
   ],
   "source": [
    "client = ToolboxSyncClient(\"http://127.0.0.1:5000\") \n",
    "\n",
    "# This will load all tools\n",
    "all_tools = client.load_toolset()\n",
    "\n",
    "print(f\"Loaded {all_tools} tools from MCP server\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b49933",
   "metadata": {},
   "source": [
    "# Create the runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17742533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global cache for runners (maintains sessions)\n",
    "_runner_cache: Dict[str, tuple] = {}\n",
    "\n",
    "async def chat_with_agent(\n",
    "    agent: Agent,\n",
    "    message: str,\n",
    "    user_id: str = \"user_001\",\n",
    "    session_id: Optional[str] = None,\n",
    "    maintain_session: bool = True,\n",
    "    verbose: bool = True\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Send a message to an agent and get the response.\n",
    "    \"\"\"\n",
    "    if session_id is None:\n",
    "        session_id = f\"{agent.name}_session\"\n",
    "    \n",
    "    app_name = f\"{agent.name}\"\n",
    "    cache_key = f\"{agent.name}_{user_id}_{session_id}\"\n",
    "    \n",
    "    # Reuse or create runner\n",
    "    if maintain_session and cache_key in _runner_cache:\n",
    "        runner = _runner_cache[cache_key]\n",
    "    else:\n",
    "        session_service = InMemorySessionService()\n",
    "        await session_service.create_session(\n",
    "            app_name=app_name,\n",
    "            user_id=user_id,\n",
    "            session_id=session_id\n",
    "        )\n",
    "        \n",
    "        runner = Runner(\n",
    "            agent=agent,\n",
    "            app_name=app_name,\n",
    "            session_service=session_service\n",
    "        )\n",
    "        \n",
    "        if maintain_session:\n",
    "            _runner_cache[cache_key] = runner\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\n>>> User Message: {message}\")\n",
    "    \n",
    "    content = types.Content(role='user', parts=[types.Part(text=message)])\n",
    "    final_response_text = None\n",
    "    \n",
    "    async for event in runner.run_async(user_id=user_id, session_id=session_id, new_message=content):\n",
    "        if verbose:\n",
    "            print(f\"[Event] Author: {event.author}, Type: {type(event).__name__}, Final: {event.is_final_response()}\")\n",
    "        \n",
    "        if event.is_final_response():\n",
    "            if event.content and event.content.parts:\n",
    "                final_response_text = event.content.parts[0].text\n",
    "            elif event.actions and event.actions.escalate:\n",
    "                final_response_text = f\"Agent escalated: {event.error_message or 'No specific message.'}\"\n",
    "            break\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"<<< Agent Response: {final_response_text}\")\n",
    "    \n",
    "    return final_response_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ec7ef6",
   "metadata": {},
   "source": [
    "# Create the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41b6a31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Agent 'agents' created successfully with 6 tools\n"
     ]
    }
   ],
   "source": [
    "db_agent = Agent(\n",
    "    name=\"agents\",\n",
    "    model=llm,\n",
    "    description=\"An intelligent database assistant for HDB resale transaction data\",\n",
    "    instruction=\"\"\"You are a helpful database assistant with access to HDB resale transaction data from 2017 onwards.\n",
    "\n",
    "**Your Role:**\n",
    "- Answer user questions using the available tools\n",
    "- Always respond in clear, natural language\n",
    "- Format prices with proper currency notation (e.g., $500,000)\n",
    "- Format large numbers with commas for readability\n",
    "\n",
    "**Response Guidelines:**\n",
    "- After calling any tool, ALWAYS provide a complete natural language summary\n",
    "- Never output raw JSON or technical data structures\n",
    "- Be conversational and helpful\n",
    "- If a query returns no results, explain this clearly\n",
    "\n",
    "**Available Data:**\n",
    "The database contains HDB resale transactions with information about prices, locations (towns), flat types, flat models, floor areas, lease dates, and transaction dates.\n",
    "\n",
    "Use the available tools intelligently to answer user questions. Each tool's description explains when to use it.\"\"\",\n",
    "    tools=all_tools,\n",
    ")\n",
    "\n",
    "print(f\"\\nAgent '{db_agent.name}' created successfully with {len(all_tools)} tools\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a393bf",
   "metadata": {},
   "source": [
    "# Chat with the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58aa3c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> User Message: What is the average resale price for 4 ROOM flats in Tampines?\n",
      "[Event] Author: agents, Type: Event, Final: False\n",
      "[Event] Author: agents, Type: Event, Final: False\n",
      "[Event] Author: agents, Type: Event, Final: True\n",
      "<<< Agent Response: \n",
      "\n",
      "The average resale price for 4 ROOM flats in Tampines is **$371,135**.\n",
      "\n",
      "This represents the average price across all 4 ROOM HDB resale transactions recorded in Tampines since 2017.\n"
     ]
    }
   ],
   "source": [
    "response_avg_tampines = await chat_with_agent(\n",
    "    db_agent, \n",
    "    \"What is the average resale price for 4 ROOM flats in Tampines?\",\n",
    "    user_id=\"user_001\",\n",
    "    maintain_session=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f4f00b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> User Message: Using the average price from the last step, how many 5 ROOM flats in Tampines have a resale price greater than that value?\n",
      "[Event] Author: agents, Type: Event, Final: False\n",
      "[Event] Author: agents, Type: Event, Final: False\n",
      "[Event] Author: agents, Type: Event, Final: True\n",
      "<<< Agent Response: \n",
      "\n",
      "Based on the data, there are **0** 5 ROOM flats in Tampines with a resale price greater than the average 4 ROOM flat price of $371,135.\n",
      "\n",
      "This indicates that 5 ROOM flats in Tampines generally have prices below the average price of 4 ROOM flats in the same area, which is an interesting finding that might suggest the specific market conditions or types of 5 ROOM properties available in Tampines.Based on the average price of $371,135 for 4 ROOM flats in Tampines, there are **0** 5 ROOM flats in Tampines with resale prices greater than that amount.\n",
      "\n",
      "This suggests that 5 ROOM flats in Tampines generally sell for less than the average price of 4 ROOM flats in the same area, which is an interesting market characteristic of Tampines.\n"
     ]
    }
   ],
   "source": [
    "response_persistence_test = await chat_with_agent(\n",
    "    db_agent, \n",
    "    \"Using the average price from the last step, how many 5 ROOM flats in Tampines have a resale price greater than that value?\",\n",
    "    user_id=\"user_001\", \n",
    "    maintain_session=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34422c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> User Message: What is the median price in Jurong West?\n",
      "[Event] Author: agents, Type: Event, Final: False\n",
      "[Event] Author: agents, Type: Event, Final: False\n",
      "[Event] Author: agents, Type: Event, Final: True\n",
      "<<< Agent Response: \n",
      "\n",
      "The median price in Jurong West is **$325,000**. This represents the middle value of all resale transaction prices in the area, meaning half of the flats sold for less than this amount and half sold for more.\n"
     ]
    }
   ],
   "source": [
    "response_switch = await chat_with_agent(\n",
    "    db_agent, \n",
    "    \"What is the median price in Jurong West?\",\n",
    "    user_id=\"user_001\", \n",
    "    maintain_session=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b83311a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> User Message: What was the average price we calculated for 4 ROOM flats in Tampines?\n",
      "[Event] Author: agents, Type: Event, Final: True\n",
      "<<< Agent Response: \n",
      "The average price we calculated for 4 ROOM flats in Tampines was **$371,135**.\n"
     ]
    }
   ],
   "source": [
    "response_memory = await chat_with_agent(\n",
    "    db_agent, \n",
    "    \"What was the average price we calculated for 4 ROOM flats in Tampines?\",\n",
    "    user_id=\"user_001\", \n",
    "    maintain_session=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2e1427c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> User Message: What is the total count of flats in Tampines?\n",
      "[Event] Author: agents, Type: Event, Final: False\n",
      "[Event] Author: agents, Type: Event, Final: False\n",
      "[Event] Author: agents, Type: Event, Final: True\n",
      "<<< Agent Response: \n",
      "Based on the HDB resale transaction data from 2017 onwards, there are **51,077** flats in Tampines.\n"
     ]
    }
   ],
   "source": [
    "response_reset = await chat_with_agent(\n",
    "  db_agent, \n",
    "  \"What is the total count of flats in Tampines?\", \n",
    "  user_id=\"user_002\",\n",
    "  session_id=None, \n",
    "  maintain_session=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46e4230",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adk-web-multi-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
